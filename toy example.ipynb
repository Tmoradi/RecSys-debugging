{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "537e3d2d-8c7b-4870-9839-9222d17c6aa5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 06:32:24.293977: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/usr/local/lib/python3.10/dist-packages/merlin/dtypes/mappings/torch.py:43: UserWarning: PyTorch dtype mappings did not load successfully due to an error: No module named 'torch'\n",
      "  warn(f\"PyTorch dtype mappings did not load successfully due to an error: {exc.msg}\")\n",
      "2024-01-12 06:32:27.136700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:27.139078: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:27.140830: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n",
      "[INFO]: sparse_operation_kit is imported\n",
      "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.base has been moved to tensorflow.python.trackable.base. The old module will be deleted in version 2.11.\n",
      "[SOK INFO] Import /usr/local/lib/python3.10/dist-packages/merlin_sok-1.2.0-py3.10-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Import /usr/local/lib/python3.10/dist-packages/merlin_sok-1.2.0-py3.10-linux-x86_64.egg/sparse_operation_kit/lib/libsok_experiment.so\n",
      "[SOK INFO] Initialize finished, communication tool: horovod\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 06:32:30.534765: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.536787: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.538478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.616736: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.618636: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.620345: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:1013] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-12 06:32:30.621953: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "2024-01-12 06:32:30.621993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1638] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7455 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import nvtabular as nvt\n",
    "from nvtabular.ops import *\n",
    "\n",
    "from merlin.models.utils.dataset import unique_rows_by_features\n",
    "from merlin.models.utils.example_utils import workflow_fit_transform\n",
    "from merlin.schema.tags import Tags\n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "\n",
    "import merlin.models.tf as mm\n",
    "from merlin.io.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "811c5941-ea3d-4135-b26d-915efab84d14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_path = '/home/jupyter/merlin_rec_sys/data/toy_dataset.parquet'\n",
    "toy = nvt.Dataset(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a33098-75cb-45b0-afd2-68e6a6b3a374",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "toy_embeddings = [f'{idx}' for idx in range(18,402)]\n",
    "toy_feedback = [f'{idx}' for idx in range(402,733)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbab90f5-f9e1-41e2-8456-d8557e235a7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#### Workflow \n",
    "userid = ['0'] >> Categorify() >> TagAsUserID()\n",
    "itemid = ['17'] >> Categorify() >> TagAsItemID()\n",
    "\n",
    "item_feats_1 = ['9','10','11','12','13','14','15','16'] >> Normalize() >> TagAsItemFeatures()\n",
    "item_feats_2 = ['8'] >> Categorify() >> TagAsItemFeatures()\n",
    "\n",
    "user_feats_1 = (['1','3','4','7']\n",
    "    >> Categorify()\n",
    "    >> TagAsUserFeatures())\n",
    "\n",
    "embeddings = toy_embeddings >> nvt.ops.AddMetadata(tags=[Tags.CONTINUOUS]) >> TagAsItemFeatures()\n",
    "\n",
    "user_feats_2 = toy_feedback >> Categorify() >> TagAsUserFeatures()\n",
    "\n",
    "user_feats_3 = ['2','5','6'] >> Normalize() >> TagAsUserFeatures()\n",
    "\n",
    "outputs = userid + itemid + item_feats_1 + item_feats_2 + user_feats_1 + embeddings + user_feats_2 + user_feats_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e3a018-6bfc-404d-ad0e-bc659fc25b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_dir = '/home/jupyter/merlin_rec_sys/data/'\n",
    "output_path = os.path.join(output_dir, \"processed_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b91a6ef8-a7e5-4171-a066-f0ed9f55e5b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow = nvt.Workflow(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c80681a-13a8-4ba1-ab02-859eaa857032",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "workflow.fit(toy)\n",
    "workflow.transform(toy).to_parquet(\n",
    "    output_path=output_path + \"/train/\",\n",
    "    out_files_per_proc = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82bc1cb-1aea-44e2-bf1e-bf1d6729663a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.save('/home/jupyter/merlin_rec_sys/data/toy_workflow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc9b8a9a-bd49-44d7-b978-4c58363ccdc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/merlin/io/parquet.py:343: UserWarning: Row group memory size (129840000) (bytes) of parquet file is bigger than requested part_size (128000000) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join(output_dir, \"processed_data\", \"*.parquet\"),part_size='128MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66db5705-bde7-4ba1-a05d-3e49d701d6b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = train.schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])\n",
    "train.schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10a274c1-df56-45e8-afea-282c8298a798",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create user schema using USER tag\n",
    "user_schema = schema.select_by_tag(Tags.USER)\n",
    "# create user (query) tower input block\n",
    "user_inputs = mm.InputBlockV2(user_schema)\n",
    "# create user (query) encoder block\n",
    "query = mm.Encoder(user_inputs, mm.MLPBlock([128,64], no_activation_last_layer=True))\n",
    "\n",
    "# create item schema using ITEM tag\n",
    "item_schema = schema.select_by_tag(Tags.ITEM)\n",
    "# create item (candidate) tower input block\n",
    "item_inputs = mm.InputBlockV2(item_schema)\n",
    "# create item (candidate) encoder block\n",
    "candidate = mm.Encoder(item_inputs, mm.MLPBlock([128,64], no_activation_last_layer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7209f87c-fa14-4168-b4d7-602f69c1f9a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-12 05:32:47.076147: I tensorflow/core/common_runtime/executor.cc:1209] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6/674 [..............................] - ETA: 18:06 - loss: 10.2708 - recall_at_10: 0.0016 - ndcg_at_10: 7.2418e-04 - regularization_loss: 0.0000e+00 - loss_batch: 10.2708WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.5913s vs `on_train_batch_end` time: 0.9650s). Check your callbacks.\n",
      "674/674 [==============================] - 1323s 2s/step - loss: 8.8668 - recall_at_10: 0.0043 - ndcg_at_10: 0.0023 - regularization_loss: 0.0000e+00 - loss_batch: 8.8610\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8d10176770>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mm.TwoTowerModelV2(query, candidate)\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10)])\n",
    "model.fit(train, batch_size=8192, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1c2dbb3c-1c07-43e9-bec9-f0bf201e1574",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) 0, 1, 2, 3, 4, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 5, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 6, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 7, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732 with unsupported characters which will be renamed to unknown, unknown_0, unknown_1, unknown_2, unknown_3, unknown_4, unknown_5, unknown_6, unknown_7, unknown_8, unknown_9, unknown_10, unknown_11, unknown_12, unknown_13, unknown_14, unknown_15, unknown_16, unknown_17, unknown_18, unknown_19, unknown_20, unknown_21, unknown_22, unknown_23, unknown_24, unknown_25, unknown_26, unknown_27, unknown_28, unknown_29, unknown_30, unknown_31, unknown_32, unknown_33, unknown_34, unknown_35, unknown_36, unknown_37, unknown_38, unknown_39, unknown_40, unknown_41, unknown_42, unknown_43, unknown_44, unknown_45, unknown_46, unknown_47, unknown_48, unknown_49, unknown_50, unknown_51, unknown_52, unknown_53, unknown_54, unknown_55, unknown_56, unknown_57, unknown_58, unknown_59, unknown_60, unknown_61, unknown_62, unknown_63, unknown_64, unknown_65, unknown_66, unknown_67, unknown_68, unknown_69, unknown_70, unknown_71, unknown_72, unknown_73, unknown_74, unknown_75, unknown_76, unknown_77, unknown_78, unknown_79, unknown_80, unknown_81, unknown_82, unknown_83, unknown_84, unknown_85, unknown_86, unknown_87, unknown_88, unknown_89, unknown_90, unknown_91, unknown_92, unknown_93, unknown_94, unknown_95, unknown_96, unknown_97, unknown_98, unknown_99, unknown_100, unknown_101, unknown_102, unknown_103, unknown_104, unknown_105, unknown_106, unknown_107, unknown_108, unknown_109, unknown_110, unknown_111, unknown_112, unknown_113, unknown_114, unknown_115, unknown_116, unknown_117, unknown_118, unknown_119, unknown_120, unknown_121, unknown_122, unknown_123, unknown_124, unknown_125, unknown_126, unknown_127, unknown_128, unknown_129, unknown_130, unknown_131, unknown_132, unknown_133, unknown_134, unknown_135, unknown_136, unknown_137, unknown_138, unknown_139, unknown_140, unknown_141, unknown_142, unknown_143, unknown_144, unknown_145, unknown_146, unknown_147, unknown_148, unknown_149, unknown_150, unknown_151, unknown_152, unknown_153, unknown_154, unknown_155, unknown_156, unknown_157, unknown_158, unknown_159, unknown_160, unknown_161, unknown_162, unknown_163, unknown_164, unknown_165, unknown_166, unknown_167, unknown_168, unknown_169, unknown_170, unknown_171, unknown_172, unknown_173, unknown_174, unknown_175, unknown_176, unknown_177, unknown_178, unknown_179, unknown_180, unknown_181, unknown_182, unknown_183, unknown_184, unknown_185, unknown_186, unknown_187, unknown_188, unknown_189, unknown_190, unknown_191, unknown_192, unknown_193, unknown_194, unknown_195, unknown_196, unknown_197, unknown_198, unknown_199, unknown_200, unknown_201, unknown_202, unknown_203, unknown_204, unknown_205, unknown_206, unknown_207, unknown_208, unknown_209, unknown_210, unknown_211, unknown_212, unknown_213, unknown_214, unknown_215, unknown_216, unknown_217, unknown_218, unknown_219, unknown_220, unknown_221, unknown_222, unknown_223, unknown_224, unknown_225, unknown_226, unknown_227, unknown_228, unknown_229, unknown_230, unknown_231, unknown_232, unknown_233, unknown_234, unknown_235, unknown_236, unknown_237, unknown_238, unknown_239, unknown_240, unknown_241, unknown_242, unknown_243, unknown_244, unknown_245, unknown_246, unknown_247, unknown_248, unknown_249, unknown_250, unknown_251, unknown_252, unknown_253, unknown_254, unknown_255, unknown_256, unknown_257, unknown_258, unknown_259, unknown_260, unknown_261, unknown_262, unknown_263, unknown_264, unknown_265, unknown_266, unknown_267, unknown_268, unknown_269, unknown_270, unknown_271, unknown_272, unknown_273, unknown_274, unknown_275, unknown_276, unknown_277, unknown_278, unknown_279, unknown_280, unknown_281, unknown_282, unknown_283, unknown_284, unknown_285, unknown_286, unknown_287, unknown_288, unknown_289, unknown_290, unknown_291, unknown_292, unknown_293, unknown_294, unknown_295, unknown_296, unknown_297, unknown_298, unknown_299, unknown_300, unknown_301, unknown_302, unknown_303, unknown_304, unknown_305, unknown_306, unknown_307, unknown_308, unknown_309, unknown_310, unknown_311, unknown_312, unknown_313, unknown_314, unknown_315, unknown_316, unknown_317, unknown_318, unknown_319, unknown_320, unknown_321, unknown_322, unknown_323, unknown_324, unknown_325, unknown_326, unknown_327, unknown_328, unknown_329, unknown_330, unknown_331, unknown_332, unknown_333, unknown_334, unknown_335, unknown_336, unknown_337 in the SavedModel.\n",
      "WARNING:absl:`0` is not a valid tf.function parameter name. Sanitizing to `arg_0`.\n",
      "WARNING:absl:`1` is not a valid tf.function parameter name. Sanitizing to `arg_1`.\n",
      "WARNING:absl:`2` is not a valid tf.function parameter name. Sanitizing to `arg_2`.\n",
      "WARNING:absl:`3` is not a valid tf.function parameter name. Sanitizing to `arg_3`.\n",
      "WARNING:absl:`4` is not a valid tf.function parameter name. Sanitizing to `arg_4`.\n",
      "WARNING:absl:Found untraced functions such as prepare_list_features_layer_call_fn, prepare_list_features_layer_call_and_return_conditional_losses, model_context_layer_call_fn, model_context_layer_call_and_return_conditional_losses, concat_features_layer_call_fn while saving (showing 5 of 1362). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jupyter/merlin_rec_sys/data/toy_query_tower/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /home/jupyter/merlin_rec_sys/data/toy_query_tower/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "query_tower = model.query_encoder\n",
    "query_tower.save(os.path.join('/home/jupyter/merlin_rec_sys/data/', \"toy_query_tower\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6772ce33-1963-4f2c-a4a8-46553bc6bc49",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer ModelContext(), because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer ModelContext(), because it is not built.\n",
      "WARNING:absl:Function `_wrapped_model` contains input name(s) 10, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 11, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 12, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 13, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 14, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 15, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 16, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 17, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 18, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 19, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 20, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 21, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 22, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 23, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 24, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 25, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 26, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 27, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 28, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 29, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 30, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 31, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 32, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 33, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 34, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 35, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 36, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 37, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 38, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 39, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 40, 400, 401, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 8, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 9, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99 with unsupported characters which will be renamed to unknown, unknown_0, unknown_1, unknown_2, unknown_3, unknown_4, unknown_5, unknown_6, unknown_7, unknown_8, unknown_9, unknown_10, unknown_11, unknown_12, unknown_13, unknown_14, unknown_15, unknown_16, unknown_17, unknown_18, unknown_19, unknown_20, unknown_21, unknown_22, unknown_23, unknown_24, unknown_25, unknown_26, unknown_27, unknown_28, unknown_29, unknown_30, unknown_31, unknown_32, unknown_33, unknown_34, unknown_35, unknown_36, unknown_37, unknown_38, unknown_39, unknown_40, unknown_41, unknown_42, unknown_43, unknown_44, unknown_45, unknown_46, unknown_47, unknown_48, unknown_49, unknown_50, unknown_51, unknown_52, unknown_53, unknown_54, unknown_55, unknown_56, unknown_57, unknown_58, unknown_59, unknown_60, unknown_61, unknown_62, unknown_63, unknown_64, unknown_65, unknown_66, unknown_67, unknown_68, unknown_69, unknown_70, unknown_71, unknown_72, unknown_73, unknown_74, unknown_75, unknown_76, unknown_77, unknown_78, unknown_79, unknown_80, unknown_81, unknown_82, unknown_83, unknown_84, unknown_85, unknown_86, unknown_87, unknown_88, unknown_89, unknown_90, unknown_91, unknown_92, unknown_93, unknown_94, unknown_95, unknown_96, unknown_97, unknown_98, unknown_99, unknown_100, unknown_101, unknown_102, unknown_103, unknown_104, unknown_105, unknown_106, unknown_107, unknown_108, unknown_109, unknown_110, unknown_111, unknown_112, unknown_113, unknown_114, unknown_115, unknown_116, unknown_117, unknown_118, unknown_119, unknown_120, unknown_121, unknown_122, unknown_123, unknown_124, unknown_125, unknown_126, unknown_127, unknown_128, unknown_129, unknown_130, unknown_131, unknown_132, unknown_133, unknown_134, unknown_135, unknown_136, unknown_137, unknown_138, unknown_139, unknown_140, unknown_141, unknown_142, unknown_143, unknown_144, unknown_145, unknown_146, unknown_147, unknown_148, unknown_149, unknown_150, unknown_151, unknown_152, unknown_153, unknown_154, unknown_155, unknown_156, unknown_157, unknown_158, unknown_159, unknown_160, unknown_161, unknown_162, unknown_163, unknown_164, unknown_165, unknown_166, unknown_167, unknown_168, unknown_169, unknown_170, unknown_171, unknown_172, unknown_173, unknown_174, unknown_175, unknown_176, unknown_177, unknown_178, unknown_179, unknown_180, unknown_181, unknown_182, unknown_183, unknown_184, unknown_185, unknown_186, unknown_187, unknown_188, unknown_189, unknown_190, unknown_191, unknown_192, unknown_193, unknown_194, unknown_195, unknown_196, unknown_197, unknown_198, unknown_199, unknown_200, unknown_201, unknown_202, unknown_203, unknown_204, unknown_205, unknown_206, unknown_207, unknown_208, unknown_209, unknown_210, unknown_211, unknown_212, unknown_213, unknown_214, unknown_215, unknown_216, unknown_217, unknown_218, unknown_219, unknown_220, unknown_221, unknown_222, unknown_223, unknown_224, unknown_225, unknown_226, unknown_227, unknown_228, unknown_229, unknown_230, unknown_231, unknown_232, unknown_233, unknown_234, unknown_235, unknown_236, unknown_237, unknown_238, unknown_239, unknown_240, unknown_241, unknown_242, unknown_243, unknown_244, unknown_245, unknown_246, unknown_247, unknown_248, unknown_249, unknown_250, unknown_251, unknown_252, unknown_253, unknown_254, unknown_255, unknown_256, unknown_257, unknown_258, unknown_259, unknown_260, unknown_261, unknown_262, unknown_263, unknown_264, unknown_265, unknown_266, unknown_267, unknown_268, unknown_269, unknown_270, unknown_271, unknown_272, unknown_273, unknown_274, unknown_275, unknown_276, unknown_277, unknown_278, unknown_279, unknown_280, unknown_281, unknown_282, unknown_283, unknown_284, unknown_285, unknown_286, unknown_287, unknown_288, unknown_289, unknown_290, unknown_291, unknown_292, unknown_293, unknown_294, unknown_295, unknown_296, unknown_297, unknown_298, unknown_299, unknown_300, unknown_301, unknown_302, unknown_303, unknown_304, unknown_305, unknown_306, unknown_307, unknown_308, unknown_309, unknown_310, unknown_311, unknown_312, unknown_313, unknown_314, unknown_315, unknown_316, unknown_317, unknown_318, unknown_319, unknown_320, unknown_321, unknown_322, unknown_323, unknown_324, unknown_325, unknown_326, unknown_327, unknown_328, unknown_329, unknown_330, unknown_331, unknown_332, unknown_333, unknown_334, unknown_335, unknown_336, unknown_337, unknown_338, unknown_339, unknown_340, unknown_341, unknown_342, unknown_343, unknown_344, unknown_345, unknown_346, unknown_347, unknown_348, unknown_349, unknown_350, unknown_351, unknown_352, unknown_353, unknown_354, unknown_355, unknown_356, unknown_357, unknown_358, unknown_359, unknown_360, unknown_361, unknown_362, unknown_363, unknown_364, unknown_365, unknown_366, unknown_367, unknown_368, unknown_369, unknown_370, unknown_371, unknown_372, unknown_373, unknown_374, unknown_375, unknown_376, unknown_377, unknown_378, unknown_379, unknown_380, unknown_381, unknown_382, unknown_383, unknown_384, unknown_385, unknown_386, unknown_387, unknown_388, unknown_389, unknown_390, unknown_391, unknown_392 in the SavedModel.\n",
      "WARNING:absl:Found untraced functions such as prepare_list_features_1_layer_call_fn, prepare_list_features_1_layer_call_and_return_conditional_losses, concat_features_1_layer_call_fn, concat_features_1_layer_call_and_return_conditional_losses, embeddings_layer_call_fn while saving (showing 5 of 24). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqxs0pdyx/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /tmp/tmpqxs0pdyx/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "std::bad_alloc: out_of_memory: CUDA error at: /usr/local/include/rmm/mr/device/cuda_memory_resource.hpp:70: cudaErrorMemoryAllocation out of memory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[1;32m      7\u001b[0m candidate_features \u001b[38;5;241m=\u001b[39m unique_rows_by_features(train, Tags\u001b[38;5;241m.\u001b[39mITEM, Tags\u001b[38;5;241m.\u001b[39mITEM_ID)\n\u001b[0;32m----> 9\u001b[0m topk_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_top_k_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py:2648\u001b[0m, in \u001b[0;36mRetrievalModelV2.to_top_k_encoder\u001b[0;34m(self, candidates, candidate_id, strategy, k, **kwargs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmerlin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TopKEncoder\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method to get a top-k encoder\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \n\u001b[1;32m   2637\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;124;03m    a given query, by default brute-force-topk\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2648\u001b[0m candidates_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2649\u001b[0m topk_model \u001b[38;5;241m=\u001b[39m TopKEncoder(\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_encoder,\n\u001b[1;32m   2651\u001b[0m     topk_layer\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2654\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mselect_by_tag(candidate_id)\u001b[38;5;241m.\u001b[39mfirst\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   2655\u001b[0m )\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m topk_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py:2539\u001b[0m, in \u001b[0;36mRetrievalModelV2.candidate_embeddings\u001b[0;34m(self, data, index, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m candidate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_encoder\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(candidate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcandidate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(candidate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidate\u001b[38;5;241m.\u001b[39mto_dataset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py:120\u001b[0m, in \u001b[0;36mEncoder.encode\u001b[0;34m(self, dataset, index, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_concat_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py:201\u001b[0m, in \u001b[0;36mEncoder.batch_predict\u001b[0;34m(self, dataset, batch_size, output_schema, index, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m     encode_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter_input_columns\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m output_schema\u001b[38;5;241m.\u001b[39mcolumn_names\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Processing a sample of the dataset with the model encoder\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;66;03m# to get the output dataframe dtypes\u001b[39;00m\n\u001b[0;32m--> 201\u001b[0m sample_output \u001b[38;5;241m=\u001b[39m model_encode(\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencode_kwargs)\n\u001b[1;32m    202\u001b[0m output_dtypes \u001b[38;5;241m=\u001b[39m sample_output\u001b[38;5;241m.\u001b[39mdtypes\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m    204\u001b[0m predictions \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mmap_partitions(model_encode, meta\u001b[38;5;241m=\u001b[39moutput_dtypes, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencode_kwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py:1268\u001b[0m, in \u001b[0;36m_Frame.head\u001b[0;34m(self, n, npartitions, compute)\u001b[0m\n\u001b[1;32m   1266\u001b[0m \u001b[38;5;66;03m# No need to warn if we're already looking at all partitions\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m safe \u001b[38;5;241m=\u001b[39m npartitions \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnpartitions\n\u001b[0;32m-> 1268\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpartitions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpartitions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msafe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafe\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py:1302\u001b[0m, in \u001b[0;36m_Frame._head\u001b[0;34m(self, n, npartitions, compute, safe)\u001b[0m\n\u001b[1;32m   1297\u001b[0m result \u001b[38;5;241m=\u001b[39m new_dd_object(\n\u001b[1;32m   1298\u001b[0m     graph, name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_meta, [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdivisions[npartitions]]\n\u001b[1;32m   1299\u001b[0m )\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compute:\n\u001b[0;32m-> 1302\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py:314\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    291\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \n\u001b[1;32m    293\u001b[0m \u001b[38;5;124;03m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    dask.base.compute\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     (result,) \u001b[38;5;241m=\u001b[39m \u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/base.py:599\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    596\u001b[0m     keys\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_keys__())\n\u001b[1;32m    597\u001b[0m     postcomputes\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39m__dask_postcompute__())\n\u001b[0;32m--> 599\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mschedule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repack([f(r, \u001b[38;5;241m*\u001b[39ma) \u001b[38;5;28;01mfor\u001b[39;00m r, (f, a) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/threaded.py:89\u001b[0m, in \u001b[0;36mget\u001b[0;34m(dsk, keys, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pool, multiprocessing\u001b[38;5;241m.\u001b[39mpool\u001b[38;5;241m.\u001b[39mPool):\n\u001b[1;32m     87\u001b[0m         pool \u001b[38;5;241m=\u001b[39m MultiprocessingPoolExecutor(pool)\n\u001b[0;32m---> 89\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mget_async\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_max_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdsk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mget_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_thread_get_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpack_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpack_exception\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# Cleanup pools associated to dead threads\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pools_lock:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:511\u001b[0m, in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    509\u001b[0m         _execute_task(task, data)  \u001b[38;5;66;03m# Re-execute locally\u001b[39;00m\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         \u001b[43mraise_exception\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    512\u001b[0m res, worker_id \u001b[38;5;241m=\u001b[39m loads(res_info)\n\u001b[1;32m    513\u001b[0m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache\u001b[39m\u001b[38;5;124m\"\u001b[39m][key] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:319\u001b[0m, in \u001b[0;36mreraise\u001b[0;34m(exc, tb)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exc\u001b[38;5;241m.\u001b[39m__traceback__ \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tb:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m--> 319\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/local.py:224\u001b[0m, in \u001b[0;36mexecute_task\u001b[0;34m(key, task_info, dumps, loads, get_id, pack_exception)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    223\u001b[0m     task, data \u001b[38;5;241m=\u001b[39m loads(task_info)\n\u001b[0;32m--> 224\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mid\u001b[39m \u001b[38;5;241m=\u001b[39m get_id()\n\u001b[1;32m    226\u001b[0m     result \u001b[38;5;241m=\u001b[39m dumps((result, \u001b[38;5;28mid\u001b[39m))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/core.py:119\u001b[0m, in \u001b[0;36m_execute_task\u001b[0;34m(arg, cache, dsk)\u001b[0m\n\u001b[1;32m    115\u001b[0m     func, args \u001b[38;5;241m=\u001b[39m arg[\u001b[38;5;241m0\u001b[39m], arg[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# Note: Don't assign the subtask results to a variable. numpy detects\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# temporaries by their reference count and can execute certain\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# operations in-place.\u001b[39;00m\n\u001b[0;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_execute_task\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ishashable(arg):\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arg\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/toolz/functoolz.py:628\u001b[0m, in \u001b[0;36mpipe\u001b[0;34m(data, *funcs)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" Pipe a value through a sequence of functions\u001b[39;00m\n\u001b[1;32m    609\u001b[0m \n\u001b[1;32m    610\u001b[0m \u001b[38;5;124;03mI.e. ``pipe(data, f, g, h)`` is equivalent to ``h(g(f(data)))``\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;124;03m    thread_last\u001b[39;00m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m funcs:\n\u001b[0;32m--> 628\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/core.py:143\u001b[0m, in \u001b[0;36m_concat\u001b[0;34m(args, ignore_index)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# We filter out empty partitions here because pandas frequently has\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# inconsistent dtypes in results between empty and non-empty frames.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;66;03m# Ideally this would be handled locally for each operation, but in practice\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# this seems easier. TODO: don't do this.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m args2 \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i)]\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m    141\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args2\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[43mmethods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muniform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask/dataframe/dispatch.py:64\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(dfs, axis, join, uniform, filter_warning, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     63\u001b[0m     func \u001b[38;5;241m=\u001b[39m concat_dispatch\u001b[38;5;241m.\u001b[39mdispatch(\u001b[38;5;28mtype\u001b[39m(dfs[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43muniform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muniform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_warning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilter_warning\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/dask_cudf/backends.py:284\u001b[0m, in \u001b[0;36mconcat_cudf\u001b[0;34m(dfs, axis, join, uniform, filter_warning, sort, ignore_index, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ignore_order:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore_order parameter is not yet supported in dask-cudf\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/cudf/core/reshape.py:406\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, sort)\u001b[0m\n\u001b[1;32m    403\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m join \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(old_objs) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(objs):\n\u001b[1;32m    404\u001b[0m             \u001b[38;5;66;03m# don't filter out empty df's\u001b[39;00m\n\u001b[1;32m    405\u001b[0m             objs \u001b[38;5;241m=\u001b[39m old_objs\n\u001b[0;32m--> 406\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_concat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m            \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m            \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m            \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# Explicitly cast rather than relying on None being falsy.\u001b[39;49;00m\n\u001b[1;32m    412\u001b[0m \u001b[43m            \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msort\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;129;01mis\u001b[39;00m cudf\u001b[38;5;241m.\u001b[39mSeries:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/nvtx/nvtx.py:115\u001b[0m, in \u001b[0;36mannotate.__call__.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     libnvtx_push_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattributes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[0;32m--> 115\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     libnvtx_pop_range(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain\u001b[38;5;241m.\u001b[39mhandle)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/cudf/core/dataframe.py:1676\u001b[0m, in \u001b[0;36mDataFrame._concat\u001b[0;34m(cls, objs, axis, join, ignore_index, sort)\u001b[0m\n\u001b[1;32m   1662\u001b[0m     tables\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m   1663\u001b[0m         DataFrame\u001b[38;5;241m.\u001b[39m_from_data(\n\u001b[1;32m   1664\u001b[0m             data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         )\n\u001b[1;32m   1672\u001b[0m     )\n\u001b[1;32m   1674\u001b[0m \u001b[38;5;66;03m# Concatenate the Tables\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_from_data(\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[43mlibcudf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat_tables\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mare_all_range_index\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1679\u001b[0m )\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;66;03m# If ignore_index is True, all input frames are empty, and at\u001b[39;00m\n\u001b[1;32m   1682\u001b[0m \u001b[38;5;66;03m# least one input frame has an index, assign a new RangeIndex\u001b[39;00m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;66;03m# to the result frame.\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m empty_has_index \u001b[38;5;129;01mand\u001b[39;00m num_empty_input_frames \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(objs):\n",
      "File \u001b[0;32m/usr/lib/python3.10/contextlib.py:79\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32mconcat.pyx:56\u001b[0m, in \u001b[0;36mcudf._lib.concat.concat_tables\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: std::bad_alloc: out_of_memory: CUDA error at: /usr/local/include/rmm/mr/device/cuda_memory_resource.hpp:70: cudaErrorMemoryAllocation out of memory"
     ]
    }
   ],
   "source": [
    "### Here we are loading the query tower. \n",
    "query_tower = tf.keras.models.load_model('/home/jupyter/merlin_rec_sys/data/toy_query_tower',compile=False)\n",
    "\n",
    "model = mm.TwoTowerModelV2(query_tower, candidate)\n",
    "model.compile()\n",
    "\n",
    "candidate_features = unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID)\n",
    "\n",
    "topk_model = model.to_top_k_encoder(candidate_features, k=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f070ccf-c6f3-4906-8977-8279e22ccaec",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Here are the errors I get w/ a restarted kernel and I load in the query tower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae19dd9-adbb-4301-8dda-cdb550504c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/merlin/io/parquet.py:343: UserWarning: Row group memory size (129840000) (bytes) of parquet file is bigger than requested part_size (128000000) for the NVTabular dataset.A row group memory size of 128 MB is generally recommended. You can find info on how to set the row group size of parquet files in https://nvidia-merlin.github.io/NVTabular/main/resources/troubleshooting.html#setting-the-row-group-size-for-the-parquet-files\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train = Dataset(os.path.join('/home/jupyter/merlin_rec_sys/data/test', \"train\", \"*.parquet\"),part_size='128MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a443fc39-c929-4b00-9e07-0866f2691912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = train.schema.select_by_tag([Tags.ITEM_ID, Tags.USER_ID, Tags.ITEM, Tags.USER])\n",
    "train.schema = schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f14964e4-e079-45d8-8284-764dbb3946f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create item schema using ITEM tag\n",
    "item_schema = schema.select_by_tag(Tags.ITEM)\n",
    "# create item (candidate) tower input block\n",
    "item_inputs = mm.InputBlockV2(item_schema)\n",
    "# create item (candidate) encoder block\n",
    "candidate = mm.Encoder(item_inputs, mm.MLPBlock([128,64], no_activation_last_layer=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f09cd27-5a84-4b59-8100-1241e02831d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_tower = tf.keras.models.load_model('/home/jupyter/merlin_rec_sys/data/toy_query_tower',compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3bb6181-5c99-4828-b5c3-869886dfab7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = mm.TwoTowerModelV2(query_tower, candidate)\n",
    "model.compile(optimizer=\"adam\", run_eagerly=False, metrics=[mm.RecallAt(10), mm.NDCGAt(10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7ce5616-cf5b-40cf-a862-92c1ea9b1942",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer Encoder(\n",
      "  (blocks): List(\n",
      "    (0): ParallelBlock(\n",
      "      (_aggregation): ConcatFeatures()\n",
      "      (parallel_layers): Dict(\n",
      "        (categorical): ParallelBlock(\n",
      "          (parallel_layers): Dict(\n",
      "            (17): EmbeddingTable(\n",
      "              (features): Dict(\n",
      "                (17): ColumnSchema(name='17', tags={<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.17.parquet', 'embedding_sizes': {'cardinality': 1378202.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 1378201, 'name': '17'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n",
      "              )\n",
      "              (table): Embedding()\n",
      "            )\n",
      "            (8): EmbeddingTable(\n",
      "              (features): Dict(\n",
      "                (8): ColumnSchema(name='8', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.8.parquet', 'embedding_sizes': {'cardinality': 7.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 6, 'name': '8'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n",
      "              )\n",
      "              (table): Embedding()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (continuous): Continuous(\n",
      "          (feature_names): List(\n",
      "            (0): '9'\n",
      "            (1): '10'\n",
      "            (2): '11'\n",
      "            (3): '12'\n",
      "            (4): '13'\n",
      "            (5): '14'\n",
      "            (6): '15'\n",
      "            (7): '16'\n",
      "            (8): '18'\n",
      "            (9): '19'\n",
      "            (10): '20'\n",
      "            (11): '21'\n",
      "            (12): '22'\n",
      "            (13): '23'\n",
      "            (14): '24'\n",
      "            (15): '25'\n",
      "            (16): '26'\n",
      "            (17): '27'\n",
      "            (18): '28'\n",
      "            (19): '29'\n",
      "            (20): '30'\n",
      "            (21): '31'\n",
      "            (22): '32'\n",
      "            (23): '33'\n",
      "            (24): '34'\n",
      "            (25): '35'\n",
      "            (26): '36'\n",
      "            (27): '37'\n",
      "            (28): '38'\n",
      "            (29): '39'\n",
      "            (30): '40'\n",
      "            (31): '41'\n",
      "            (32): '42'\n",
      "            (33): '43'\n",
      "            (34): '44'\n",
      "            (35): '45'\n",
      "            (36): '46'\n",
      "            (37): '47'\n",
      "            (38): '48'\n",
      "            (39): '49'\n",
      "            (40): '50'\n",
      "            (41): '51'\n",
      "            (42): '52'\n",
      "            (43): '53'\n",
      "            (44): '54'\n",
      "            (45): '55'\n",
      "            (46): '56'\n",
      "            (47): '57'\n",
      "            (48): '58'\n",
      "            (49): '59'\n",
      "            (50): '60'\n",
      "            (51): '61'\n",
      "            (52): '62'\n",
      "            (53): '63'\n",
      "            (54): '64'\n",
      "            (55): '65'\n",
      "            (56): '66'\n",
      "            (57): '67'\n",
      "            (58): '68'\n",
      "            (59): '69'\n",
      "            (60): '70'\n",
      "            (61): '71'\n",
      "            (62): '72'\n",
      "            (63): '73'\n",
      "            (64): '74'\n",
      "            (65): '75'\n",
      "            (66): '76'\n",
      "            (67): '77'\n",
      "            (68): '78'\n",
      "            (69): '79'\n",
      "            (70): '80'\n",
      "            (71): '81'\n",
      "            (72): '82'\n",
      "            (73): '83'\n",
      "            (74): '84'\n",
      "            (75): '85'\n",
      "            (76): '86'\n",
      "            (77): '87'\n",
      "            (78): '88'\n",
      "            (79): '89'\n",
      "            (80): '90'\n",
      "            (81): '91'\n",
      "            (82): '92'\n",
      "            (83): '93'\n",
      "            (84): '94'\n",
      "            (85): '95'\n",
      "            (86): '96'\n",
      "            (87): '97'\n",
      "            (88): '98'\n",
      "            (89): '99'\n",
      "            (90): '100'\n",
      "            (91): '101'\n",
      "            (92): '102'\n",
      "            (93): '103'\n",
      "            (94): '104'\n",
      "            (95): '105'\n",
      "            (96): '106'\n",
      "            (97): '107'\n",
      "            (98): '108'\n",
      "            (99): '109'\n",
      "            (100): '110'\n",
      "            (101): '111'\n",
      "            (102): '112'\n",
      "            (103): '113'\n",
      "            (104): '114'\n",
      "            (105): '115'\n",
      "            (106): '116'\n",
      "            (107): '117'\n",
      "            (108): '118'\n",
      "            (109): '119'\n",
      "            (110): '120'\n",
      "            (111): '121'\n",
      "            (112): '122'\n",
      "            (113): '123'\n",
      "            (114): '124'\n",
      "            (115): '125'\n",
      "            (116): '126'\n",
      "            (117): '127'\n",
      "            (118): '128'\n",
      "            (119): '129'\n",
      "            (120): '130'\n",
      "            (121): '131'\n",
      "            (122): '132'\n",
      "            (123): '133'\n",
      "            (124): '134'\n",
      "            (125): '135'\n",
      "            (126): '136'\n",
      "            (127): '137'\n",
      "            (128): '138'\n",
      "            (129): '139'\n",
      "            (130): '140'\n",
      "            (131): '141'\n",
      "            (132): '142'\n",
      "            (133): '143'\n",
      "            (134): '144'\n",
      "            (135): '145'\n",
      "            (136): '146'\n",
      "            (137): '147'\n",
      "            (138): '148'\n",
      "            (139): '149'\n",
      "            (140): '150'\n",
      "            (141): '151'\n",
      "            (142): '152'\n",
      "            (143): '153'\n",
      "            (144): '154'\n",
      "            (145): '155'\n",
      "            (146): '156'\n",
      "            (147): '157'\n",
      "            (148): '158'\n",
      "            (149): '159'\n",
      "            (150): '160'\n",
      "            (151): '161'\n",
      "            (152): '162'\n",
      "            (153): '163'\n",
      "            (154): '164'\n",
      "            (155): '165'\n",
      "            (156): '166'\n",
      "            (157): '167'\n",
      "            (158): '168'\n",
      "            (159): '169'\n",
      "            (160): '170'\n",
      "            (161): '171'\n",
      "            (162): '172'\n",
      "            (163): '173'\n",
      "            (164): '174'\n",
      "            (165): '175'\n",
      "            (166): '176'\n",
      "            (167): '177'\n",
      "            (168): '178'\n",
      "            (169): '179'\n",
      "            (170): '180'\n",
      "            (171): '181'\n",
      "            (172): '182'\n",
      "            (173): '183'\n",
      "            (174): '184'\n",
      "            (175): '185'\n",
      "            (176): '186'\n",
      "            (177): '187'\n",
      "            (178): '188'\n",
      "            (179): '189'\n",
      "            (180): '190'\n",
      "            (181): '191'\n",
      "            (182): '192'\n",
      "            (183): '193'\n",
      "            (184): '194'\n",
      "            (185): '195'\n",
      "            (186): '196'\n",
      "            (187): '197'\n",
      "            (188): '198'\n",
      "            (189): '199'\n",
      "            (190): '200'\n",
      "            (191): '201'\n",
      "            (192): '202'\n",
      "            (193): '203'\n",
      "            (194): '204'\n",
      "            (195): '205'\n",
      "            (196): '206'\n",
      "            (197): '207'\n",
      "            (198): '208'\n",
      "            (199): '209'\n",
      "            (200): '210'\n",
      "            (201): '211'\n",
      "            (202): '212'\n",
      "            (203): '213'\n",
      "            (204): '214'\n",
      "            (205): '215'\n",
      "            (206): '216'\n",
      "            (207): '217'\n",
      "            (208): '218'\n",
      "            (209): '219'\n",
      "            (210): '220'\n",
      "            (211): '221'\n",
      "            (212): '222'\n",
      "            (213): '223'\n",
      "            (214): '224'\n",
      "            (215): '225'\n",
      "            (216): '226'\n",
      "            (217): '227'\n",
      "            (218): '228'\n",
      "            (219): '229'\n",
      "            (220): '230'\n",
      "            (221): '231'\n",
      "            (222): '232'\n",
      "            (223): '233'\n",
      "            (224): '234'\n",
      "            (225): '235'\n",
      "            (226): '236'\n",
      "            (227): '237'\n",
      "            (228): '238'\n",
      "            (229): '239'\n",
      "            (230): '240'\n",
      "            (231): '241'\n",
      "            (232): '242'\n",
      "            (233): '243'\n",
      "            (234): '244'\n",
      "            (235): '245'\n",
      "            (236): '246'\n",
      "            (237): '247'\n",
      "            (238): '248'\n",
      "            (239): '249'\n",
      "            (240): '250'\n",
      "            (241): '251'\n",
      "            (242): '252'\n",
      "            (243): '253'\n",
      "            (244): '254'\n",
      "            (245): '255'\n",
      "            (246): '256'\n",
      "            (247): '257'\n",
      "            (248): '258'\n",
      "            (249): '259'\n",
      "            (250): '260'\n",
      "            (251): '261'\n",
      "            (252): '262'\n",
      "            (253): '263'\n",
      "            (254): '264'\n",
      "            (255): '265'\n",
      "            (256): '266'\n",
      "            (257): '267'\n",
      "            (258): '268'\n",
      "            (259): '269'\n",
      "            (260): '270'\n",
      "            (261): '271'\n",
      "            (262): '272'\n",
      "            (263): '273'\n",
      "            (264): '274'\n",
      "            (265): '275'\n",
      "            (266): '276'\n",
      "            (267): '277'\n",
      "            (268): '278'\n",
      "            (269): '279'\n",
      "            (270): '280'\n",
      "            (271): '281'\n",
      "            (272): '282'\n",
      "            (273): '283'\n",
      "            (274): '284'\n",
      "            (275): '285'\n",
      "            (276): '286'\n",
      "            (277): '287'\n",
      "            (278): '288'\n",
      "            (279): '289'\n",
      "            (280): '290'\n",
      "            (281): '291'\n",
      "            (282): '292'\n",
      "            (283): '293'\n",
      "            (284): '294'\n",
      "            (285): '295'\n",
      "            (286): '296'\n",
      "            (287): '297'\n",
      "            (288): '298'\n",
      "            (289): '299'\n",
      "            (290): '300'\n",
      "            (291): '301'\n",
      "            (292): '302'\n",
      "            (293): '303'\n",
      "            (294): '304'\n",
      "            (295): '305'\n",
      "            (296): '306'\n",
      "            (297): '307'\n",
      "            (298): '308'\n",
      "            (299): '309'\n",
      "            (300): '310'\n",
      "            (301): '311'\n",
      "            (302): '312'\n",
      "            (303): '313'\n",
      "            (304): '314'\n",
      "            (305): '315'\n",
      "            (306): '316'\n",
      "            (307): '317'\n",
      "            (308): '318'\n",
      "            (309): '319'\n",
      "            (310): '320'\n",
      "            (311): '321'\n",
      "            (312): '322'\n",
      "            (313): '323'\n",
      "            (314): '324'\n",
      "            (315): '325'\n",
      "            (316): '326'\n",
      "            (317): '327'\n",
      "            (318): '328'\n",
      "            (319): '329'\n",
      "            (320): '330'\n",
      "            (321): '331'\n",
      "            (322): '332'\n",
      "            (323): '333'\n",
      "            (324): '334'\n",
      "            (325): '335'\n",
      "            (326): '336'\n",
      "            (327): '337'\n",
      "            (328): '338'\n",
      "            (329): '339'\n",
      "            (330): '340'\n",
      "            (331): '341'\n",
      "            (332): '342'\n",
      "            (333): '343'\n",
      "            (334): '344'\n",
      "            (335): '345'\n",
      "            (336): '346'\n",
      "            (337): '347'\n",
      "            (338): '348'\n",
      "            (339): '349'\n",
      "            (340): '350'\n",
      "            (341): '351'\n",
      "            (342): '352'\n",
      "            (343): '353'\n",
      "            (344): '354'\n",
      "            (345): '355'\n",
      "            (346): '356'\n",
      "            (347): '357'\n",
      "            (348): '358'\n",
      "            (349): '359'\n",
      "            (350): '360'\n",
      "            (351): '361'\n",
      "            (352): '362'\n",
      "            (353): '363'\n",
      "            (354): '364'\n",
      "            (355): '365'\n",
      "            (356): '366'\n",
      "            (357): '367'\n",
      "            (358): '368'\n",
      "            (359): '369'\n",
      "            (360): '370'\n",
      "            (361): '371'\n",
      "            (362): '372'\n",
      "            (363): '373'\n",
      "            (364): '374'\n",
      "            (365): '375'\n",
      "            (366): '376'\n",
      "            (367): '377'\n",
      "            (368): '378'\n",
      "            (369): '379'\n",
      "            (370): '380'\n",
      "            (371): '381'\n",
      "            (372): '382'\n",
      "            (373): '383'\n",
      "            (374): '384'\n",
      "            (375): '385'\n",
      "            (376): '386'\n",
      "            (377): '387'\n",
      "            (378): '388'\n",
      "            (379): '389'\n",
      "            (380): '390'\n",
      "            (381): '391'\n",
      "            (382): '392'\n",
      "            (383): '393'\n",
      "            (384): '394'\n",
      "            (385): '395'\n",
      "            (386): '396'\n",
      "            (387): '397'\n",
      "            (388): '398'\n",
      "            (389): '399'\n",
      "            (390): '400'\n",
      "            (391): '401'\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): MLPBlock(\n",
      "      (layers): List(\n",
      "        (0): _Dense(\n",
      "          (dense): Dense(128, activation=relu, use_bias=True)\n",
      "        )\n",
      "        (1): _Dense(\n",
      "          (dense): Dense(64, activation=linear, use_bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (_prepare_features): PrepareFeatures(\n",
      "    (prepare_lists): PrepareListFeatures()\n",
      "  )\n",
      "), because it is not built.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Model Encoder(\n  (blocks): List(\n    (0): ParallelBlock(\n      (_aggregation): ConcatFeatures()\n      (parallel_layers): Dict(\n        (categorical): ParallelBlock(\n          (parallel_layers): Dict(\n            (17): EmbeddingTable(\n              (features): Dict(\n                (17): ColumnSchema(name='17', tags={<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.17.parquet', 'embedding_sizes': {'cardinality': 1378202.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 1378201, 'name': '17'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n              )\n              (table): Embedding()\n            )\n            (8): EmbeddingTable(\n              (features): Dict(\n                (8): ColumnSchema(name='8', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.8.parquet', 'embedding_sizes': {'cardinality': 7.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 6, 'name': '8'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n              )\n              (table): Embedding()\n            )\n          )\n        )\n        (continuous): Continuous(\n          (feature_names): List(\n            (0): '9'\n            (1): '10'\n            (2): '11'\n            (3): '12'\n            (4): '13'\n            (5): '14'\n            (6): '15'\n            (7): '16'\n            (8): '18'\n            (9): '19'\n            (10): '20'\n            (11): '21'\n            (12): '22'\n            (13): '23'\n            (14): '24'\n            (15): '25'\n            (16): '26'\n            (17): '27'\n            (18): '28'\n            (19): '29'\n            (20): '30'\n            (21): '31'\n            (22): '32'\n            (23): '33'\n            (24): '34'\n            (25): '35'\n            (26): '36'\n            (27): '37'\n            (28): '38'\n            (29): '39'\n            (30): '40'\n            (31): '41'\n            (32): '42'\n            (33): '43'\n            (34): '44'\n            (35): '45'\n            (36): '46'\n            (37): '47'\n            (38): '48'\n            (39): '49'\n            (40): '50'\n            (41): '51'\n            (42): '52'\n            (43): '53'\n            (44): '54'\n            (45): '55'\n            (46): '56'\n            (47): '57'\n            (48): '58'\n            (49): '59'\n            (50): '60'\n            (51): '61'\n            (52): '62'\n            (53): '63'\n            (54): '64'\n            (55): '65'\n            (56): '66'\n            (57): '67'\n            (58): '68'\n            (59): '69'\n            (60): '70'\n            (61): '71'\n            (62): '72'\n            (63): '73'\n            (64): '74'\n            (65): '75'\n            (66): '76'\n            (67): '77'\n            (68): '78'\n            (69): '79'\n            (70): '80'\n            (71): '81'\n            (72): '82'\n            (73): '83'\n            (74): '84'\n            (75): '85'\n            (76): '86'\n            (77): '87'\n            (78): '88'\n            (79): '89'\n            (80): '90'\n            (81): '91'\n            (82): '92'\n            (83): '93'\n            (84): '94'\n            (85): '95'\n            (86): '96'\n            (87): '97'\n            (88): '98'\n            (89): '99'\n            (90): '100'\n            (91): '101'\n            (92): '102'\n            (93): '103'\n            (94): '104'\n            (95): '105'\n            (96): '106'\n            (97): '107'\n            (98): '108'\n            (99): '109'\n            (100): '110'\n            (101): '111'\n            (102): '112'\n            (103): '113'\n            (104): '114'\n            (105): '115'\n            (106): '116'\n            (107): '117'\n            (108): '118'\n            (109): '119'\n            (110): '120'\n            (111): '121'\n            (112): '122'\n            (113): '123'\n            (114): '124'\n            (115): '125'\n            (116): '126'\n            (117): '127'\n            (118): '128'\n            (119): '129'\n            (120): '130'\n            (121): '131'\n            (122): '132'\n            (123): '133'\n            (124): '134'\n            (125): '135'\n            (126): '136'\n            (127): '137'\n            (128): '138'\n            (129): '139'\n            (130): '140'\n            (131): '141'\n            (132): '142'\n            (133): '143'\n            (134): '144'\n            (135): '145'\n            (136): '146'\n            (137): '147'\n            (138): '148'\n            (139): '149'\n            (140): '150'\n            (141): '151'\n            (142): '152'\n            (143): '153'\n            (144): '154'\n            (145): '155'\n            (146): '156'\n            (147): '157'\n            (148): '158'\n            (149): '159'\n            (150): '160'\n            (151): '161'\n            (152): '162'\n            (153): '163'\n            (154): '164'\n            (155): '165'\n            (156): '166'\n            (157): '167'\n            (158): '168'\n            (159): '169'\n            (160): '170'\n            (161): '171'\n            (162): '172'\n            (163): '173'\n            (164): '174'\n            (165): '175'\n            (166): '176'\n            (167): '177'\n            (168): '178'\n            (169): '179'\n            (170): '180'\n            (171): '181'\n            (172): '182'\n            (173): '183'\n            (174): '184'\n            (175): '185'\n            (176): '186'\n            (177): '187'\n            (178): '188'\n            (179): '189'\n            (180): '190'\n            (181): '191'\n            (182): '192'\n            (183): '193'\n            (184): '194'\n            (185): '195'\n            (186): '196'\n            (187): '197'\n            (188): '198'\n            (189): '199'\n            (190): '200'\n            (191): '201'\n            (192): '202'\n            (193): '203'\n            (194): '204'\n            (195): '205'\n            (196): '206'\n            (197): '207'\n            (198): '208'\n            (199): '209'\n            (200): '210'\n            (201): '211'\n            (202): '212'\n            (203): '213'\n            (204): '214'\n            (205): '215'\n            (206): '216'\n            (207): '217'\n            (208): '218'\n            (209): '219'\n            (210): '220'\n            (211): '221'\n            (212): '222'\n            (213): '223'\n            (214): '224'\n            (215): '225'\n            (216): '226'\n            (217): '227'\n            (218): '228'\n            (219): '229'\n            (220): '230'\n            (221): '231'\n            (222): '232'\n            (223): '233'\n            (224): '234'\n            (225): '235'\n            (226): '236'\n            (227): '237'\n            (228): '238'\n            (229): '239'\n            (230): '240'\n            (231): '241'\n            (232): '242'\n            (233): '243'\n            (234): '244'\n            (235): '245'\n            (236): '246'\n            (237): '247'\n            (238): '248'\n            (239): '249'\n            (240): '250'\n            (241): '251'\n            (242): '252'\n            (243): '253'\n            (244): '254'\n            (245): '255'\n            (246): '256'\n            (247): '257'\n            (248): '258'\n            (249): '259'\n            (250): '260'\n            (251): '261'\n            (252): '262'\n            (253): '263'\n            (254): '264'\n            (255): '265'\n            (256): '266'\n            (257): '267'\n            (258): '268'\n            (259): '269'\n            (260): '270'\n            (261): '271'\n            (262): '272'\n            (263): '273'\n            (264): '274'\n            (265): '275'\n            (266): '276'\n            (267): '277'\n            (268): '278'\n            (269): '279'\n            (270): '280'\n            (271): '281'\n            (272): '282'\n            (273): '283'\n            (274): '284'\n            (275): '285'\n            (276): '286'\n            (277): '287'\n            (278): '288'\n            (279): '289'\n            (280): '290'\n            (281): '291'\n            (282): '292'\n            (283): '293'\n            (284): '294'\n            (285): '295'\n            (286): '296'\n            (287): '297'\n            (288): '298'\n            (289): '299'\n            (290): '300'\n            (291): '301'\n            (292): '302'\n            (293): '303'\n            (294): '304'\n            (295): '305'\n            (296): '306'\n            (297): '307'\n            (298): '308'\n            (299): '309'\n            (300): '310'\n            (301): '311'\n            (302): '312'\n            (303): '313'\n            (304): '314'\n            (305): '315'\n            (306): '316'\n            (307): '317'\n            (308): '318'\n            (309): '319'\n            (310): '320'\n            (311): '321'\n            (312): '322'\n            (313): '323'\n            (314): '324'\n            (315): '325'\n            (316): '326'\n            (317): '327'\n            (318): '328'\n            (319): '329'\n            (320): '330'\n            (321): '331'\n            (322): '332'\n            (323): '333'\n            (324): '334'\n            (325): '335'\n            (326): '336'\n            (327): '337'\n            (328): '338'\n            (329): '339'\n            (330): '340'\n            (331): '341'\n            (332): '342'\n            (333): '343'\n            (334): '344'\n            (335): '345'\n            (336): '346'\n            (337): '347'\n            (338): '348'\n            (339): '349'\n            (340): '350'\n            (341): '351'\n            (342): '352'\n            (343): '353'\n            (344): '354'\n            (345): '355'\n            (346): '356'\n            (347): '357'\n            (348): '358'\n            (349): '359'\n            (350): '360'\n            (351): '361'\n            (352): '362'\n            (353): '363'\n            (354): '364'\n            (355): '365'\n            (356): '366'\n            (357): '367'\n            (358): '368'\n            (359): '369'\n            (360): '370'\n            (361): '371'\n            (362): '372'\n            (363): '373'\n            (364): '374'\n            (365): '375'\n            (366): '376'\n            (367): '377'\n            (368): '378'\n            (369): '379'\n            (370): '380'\n            (371): '381'\n            (372): '382'\n            (373): '383'\n            (374): '384'\n            (375): '385'\n            (376): '386'\n            (377): '387'\n            (378): '388'\n            (379): '389'\n            (380): '390'\n            (381): '391'\n            (382): '392'\n            (383): '393'\n            (384): '394'\n            (385): '395'\n            (386): '396'\n            (387): '397'\n            (388): '398'\n            (389): '399'\n            (390): '400'\n            (391): '401'\n          )\n        )\n      )\n    )\n    (1): MLPBlock(\n      (layers): List(\n        (0): _Dense(\n          (dense): Dense(128, activation=relu, use_bias=True)\n        )\n        (1): _Dense(\n          (dense): Dense(64, activation=linear, use_bias=True)\n        )\n      )\n    )\n  )\n  (_prepare_features): PrepareFeatures(\n    (prepare_lists): PrepareListFeatures()\n  )\n) cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m candidate_features \u001b[38;5;241m=\u001b[39m unique_rows_by_features(train, Tags\u001b[38;5;241m.\u001b[39mITEM, Tags\u001b[38;5;241m.\u001b[39mITEM_ID)\n\u001b[0;32m----> 3\u001b[0m topk_model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_top_k_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py:2648\u001b[0m, in \u001b[0;36mRetrievalModelV2.to_top_k_encoder\u001b[0;34m(self, candidates, candidate_id, strategy, k, **kwargs)\u001b[0m\n\u001b[1;32m   2633\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmerlin\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtf\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mencoder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TopKEncoder\n\u001b[1;32m   2635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Method to get a top-k encoder\u001b[39;00m\n\u001b[1;32m   2636\u001b[0m \n\u001b[1;32m   2637\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2646\u001b[0m \u001b[38;5;124;03m    a given query, by default brute-force-topk\u001b[39;00m\n\u001b[1;32m   2647\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2648\u001b[0m candidates_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcandidate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcandidate_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2649\u001b[0m topk_model \u001b[38;5;241m=\u001b[39m TopKEncoder(\n\u001b[1;32m   2650\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_encoder,\n\u001b[1;32m   2651\u001b[0m     topk_layer\u001b[38;5;241m=\u001b[39mstrategy,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2654\u001b[0m     target\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39m_schema\u001b[38;5;241m.\u001b[39mselect_by_tag(candidate_id)\u001b[38;5;241m.\u001b[39mfirst\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m   2655\u001b[0m )\n\u001b[1;32m   2656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m topk_model\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/models/base.py:2539\u001b[0m, in \u001b[0;36mRetrievalModelV2.candidate_embeddings\u001b[0;34m(self, data, index, **kwargs)\u001b[0m\n\u001b[1;32m   2536\u001b[0m candidate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_encoder\n\u001b[1;32m   2538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(candidate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencode\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 2539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcandidate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2541\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(candidate, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   2542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m candidate\u001b[38;5;241m.\u001b[39mto_dataset(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py:120\u001b[0m, in \u001b[0;36mEncoder.encode\u001b[0;34m(self, dataset, index, batch_size, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid index: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_predict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    123\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_schema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_concat_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py:187\u001b[0m, in \u001b[0;36mEncoder.batch_predict\u001b[0;34m(self, dataset, batch_size, output_schema, index, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(dataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_ddf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    185\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mto_ddf()\n\u001b[0;32m--> 187\u001b[0m model_encode \u001b[38;5;241m=\u001b[39m \u001b[43mTFModelEncode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloader_transforms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloader_transforms\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_schema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m encode_kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_schema:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/utils/batch_utils.py:80\u001b[0m, in \u001b[0;36mTFModelEncode.__init__\u001b[0;34m(self, model, output_names, batch_size, save_path, block_load_func, schema, output_concat_func, loader_transforms)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     70\u001b[0m     model: tp\u001b[38;5;241m.\u001b[39mUnion[Model, tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mModel],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     77\u001b[0m     loader_transforms\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     78\u001b[0m ):\n\u001b[1;32m     79\u001b[0m     save_path \u001b[38;5;241m=\u001b[39m save_path \u001b[38;5;129;01mor\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mmkdtemp()\n\u001b[0;32m---> 80\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     model_load_func \u001b[38;5;241m=\u001b[39m block_load_func \u001b[38;5;28;01mif\u001b[39;00m block_load_func \u001b[38;5;28;01melse\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmodels\u001b[38;5;241m.\u001b[39mload_model\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m output_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, Model):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/merlin/models/tf/core/encoder.py:335\u001b[0m, in \u001b[0;36mEncoder.save\u001b[0;34m(self, export_path, include_optimizer, save_traces)\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msave\u001b[39m(\n\u001b[1;32m    316\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    317\u001b[0m     export_path: Union[\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike],\n\u001b[1;32m    318\u001b[0m     include_optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    319\u001b[0m     save_traces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    320\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Saves the model to export_path as a Tensorflow Saved Model.\u001b[39;00m\n\u001b[1;32m    322\u001b[0m \u001b[38;5;124;03m    Along with merlin model metadata.\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m        stored, by default True\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexport_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43minclude_optimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude_optimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_traces\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_traces\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m     input_schema \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema\n\u001b[1;32m    342\u001b[0m     output_schema \u001b[38;5;241m=\u001b[39m get_output_schema(export_path)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/saving_utils.py:97\u001b[0m, in \u001b[0;36mraise_model_input_error\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     89\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved because the input shape is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     90\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable. Please specify an input shape either by calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`build(input_shape)` directly, or by calling the model on actual \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata using `Model()`, `Model.fit()`, or `Model.predict()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[1;32m     95\u001b[0m \u001b[38;5;66;03m# If the model is not a `Sequential`, it is intended to be a subclassed\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m cannot be saved either because the input shape is not \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mavailable or because the forward pass of the model is not defined.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo define a forward pass, please override `Model.call()`. To specify \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man input shape, either call `build(input_shape)` directly, or call \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe model on actual data using `Model()`, `Model.fit()`, or \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.predict()`. If you have a custom training step, please make \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msure to invoke the forward pass in train step through \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    106\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: Model Encoder(\n  (blocks): List(\n    (0): ParallelBlock(\n      (_aggregation): ConcatFeatures()\n      (parallel_layers): Dict(\n        (categorical): ParallelBlock(\n          (parallel_layers): Dict(\n            (17): EmbeddingTable(\n              (features): Dict(\n                (17): ColumnSchema(name='17', tags={<Tags.ID: 'id'>, <Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.17.parquet', 'embedding_sizes': {'cardinality': 1378202.0, 'dimension': 512.0}, 'domain': {'min': 0, 'max': 1378201, 'name': '17'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n              )\n              (table): Embedding()\n            )\n            (8): EmbeddingTable(\n              (features): Dict(\n                (8): ColumnSchema(name='8', tags={<Tags.ITEM: 'item'>, <Tags.CATEGORICAL: 'categorical'>}, properties={'num_buckets': None, 'freq_threshold': 0.0, 'max_size': 0.0, 'cat_path': './/categories/unique.8.parquet', 'embedding_sizes': {'cardinality': 7.0, 'dimension': 16.0}, 'domain': {'min': 0, 'max': 6, 'name': '8'}}, dtype=DType(name='int64', element_type=<ElementType.Int: 'int'>, element_size=64, element_unit=None, signed=True, shape=Shape(dims=(Dimension(min=0, max=None),))), is_list=False, is_ragged=False)\n              )\n              (table): Embedding()\n            )\n          )\n        )\n        (continuous): Continuous(\n          (feature_names): List(\n            (0): '9'\n            (1): '10'\n            (2): '11'\n            (3): '12'\n            (4): '13'\n            (5): '14'\n            (6): '15'\n            (7): '16'\n            (8): '18'\n            (9): '19'\n            (10): '20'\n            (11): '21'\n            (12): '22'\n            (13): '23'\n            (14): '24'\n            (15): '25'\n            (16): '26'\n            (17): '27'\n            (18): '28'\n            (19): '29'\n            (20): '30'\n            (21): '31'\n            (22): '32'\n            (23): '33'\n            (24): '34'\n            (25): '35'\n            (26): '36'\n            (27): '37'\n            (28): '38'\n            (29): '39'\n            (30): '40'\n            (31): '41'\n            (32): '42'\n            (33): '43'\n            (34): '44'\n            (35): '45'\n            (36): '46'\n            (37): '47'\n            (38): '48'\n            (39): '49'\n            (40): '50'\n            (41): '51'\n            (42): '52'\n            (43): '53'\n            (44): '54'\n            (45): '55'\n            (46): '56'\n            (47): '57'\n            (48): '58'\n            (49): '59'\n            (50): '60'\n            (51): '61'\n            (52): '62'\n            (53): '63'\n            (54): '64'\n            (55): '65'\n            (56): '66'\n            (57): '67'\n            (58): '68'\n            (59): '69'\n            (60): '70'\n            (61): '71'\n            (62): '72'\n            (63): '73'\n            (64): '74'\n            (65): '75'\n            (66): '76'\n            (67): '77'\n            (68): '78'\n            (69): '79'\n            (70): '80'\n            (71): '81'\n            (72): '82'\n            (73): '83'\n            (74): '84'\n            (75): '85'\n            (76): '86'\n            (77): '87'\n            (78): '88'\n            (79): '89'\n            (80): '90'\n            (81): '91'\n            (82): '92'\n            (83): '93'\n            (84): '94'\n            (85): '95'\n            (86): '96'\n            (87): '97'\n            (88): '98'\n            (89): '99'\n            (90): '100'\n            (91): '101'\n            (92): '102'\n            (93): '103'\n            (94): '104'\n            (95): '105'\n            (96): '106'\n            (97): '107'\n            (98): '108'\n            (99): '109'\n            (100): '110'\n            (101): '111'\n            (102): '112'\n            (103): '113'\n            (104): '114'\n            (105): '115'\n            (106): '116'\n            (107): '117'\n            (108): '118'\n            (109): '119'\n            (110): '120'\n            (111): '121'\n            (112): '122'\n            (113): '123'\n            (114): '124'\n            (115): '125'\n            (116): '126'\n            (117): '127'\n            (118): '128'\n            (119): '129'\n            (120): '130'\n            (121): '131'\n            (122): '132'\n            (123): '133'\n            (124): '134'\n            (125): '135'\n            (126): '136'\n            (127): '137'\n            (128): '138'\n            (129): '139'\n            (130): '140'\n            (131): '141'\n            (132): '142'\n            (133): '143'\n            (134): '144'\n            (135): '145'\n            (136): '146'\n            (137): '147'\n            (138): '148'\n            (139): '149'\n            (140): '150'\n            (141): '151'\n            (142): '152'\n            (143): '153'\n            (144): '154'\n            (145): '155'\n            (146): '156'\n            (147): '157'\n            (148): '158'\n            (149): '159'\n            (150): '160'\n            (151): '161'\n            (152): '162'\n            (153): '163'\n            (154): '164'\n            (155): '165'\n            (156): '166'\n            (157): '167'\n            (158): '168'\n            (159): '169'\n            (160): '170'\n            (161): '171'\n            (162): '172'\n            (163): '173'\n            (164): '174'\n            (165): '175'\n            (166): '176'\n            (167): '177'\n            (168): '178'\n            (169): '179'\n            (170): '180'\n            (171): '181'\n            (172): '182'\n            (173): '183'\n            (174): '184'\n            (175): '185'\n            (176): '186'\n            (177): '187'\n            (178): '188'\n            (179): '189'\n            (180): '190'\n            (181): '191'\n            (182): '192'\n            (183): '193'\n            (184): '194'\n            (185): '195'\n            (186): '196'\n            (187): '197'\n            (188): '198'\n            (189): '199'\n            (190): '200'\n            (191): '201'\n            (192): '202'\n            (193): '203'\n            (194): '204'\n            (195): '205'\n            (196): '206'\n            (197): '207'\n            (198): '208'\n            (199): '209'\n            (200): '210'\n            (201): '211'\n            (202): '212'\n            (203): '213'\n            (204): '214'\n            (205): '215'\n            (206): '216'\n            (207): '217'\n            (208): '218'\n            (209): '219'\n            (210): '220'\n            (211): '221'\n            (212): '222'\n            (213): '223'\n            (214): '224'\n            (215): '225'\n            (216): '226'\n            (217): '227'\n            (218): '228'\n            (219): '229'\n            (220): '230'\n            (221): '231'\n            (222): '232'\n            (223): '233'\n            (224): '234'\n            (225): '235'\n            (226): '236'\n            (227): '237'\n            (228): '238'\n            (229): '239'\n            (230): '240'\n            (231): '241'\n            (232): '242'\n            (233): '243'\n            (234): '244'\n            (235): '245'\n            (236): '246'\n            (237): '247'\n            (238): '248'\n            (239): '249'\n            (240): '250'\n            (241): '251'\n            (242): '252'\n            (243): '253'\n            (244): '254'\n            (245): '255'\n            (246): '256'\n            (247): '257'\n            (248): '258'\n            (249): '259'\n            (250): '260'\n            (251): '261'\n            (252): '262'\n            (253): '263'\n            (254): '264'\n            (255): '265'\n            (256): '266'\n            (257): '267'\n            (258): '268'\n            (259): '269'\n            (260): '270'\n            (261): '271'\n            (262): '272'\n            (263): '273'\n            (264): '274'\n            (265): '275'\n            (266): '276'\n            (267): '277'\n            (268): '278'\n            (269): '279'\n            (270): '280'\n            (271): '281'\n            (272): '282'\n            (273): '283'\n            (274): '284'\n            (275): '285'\n            (276): '286'\n            (277): '287'\n            (278): '288'\n            (279): '289'\n            (280): '290'\n            (281): '291'\n            (282): '292'\n            (283): '293'\n            (284): '294'\n            (285): '295'\n            (286): '296'\n            (287): '297'\n            (288): '298'\n            (289): '299'\n            (290): '300'\n            (291): '301'\n            (292): '302'\n            (293): '303'\n            (294): '304'\n            (295): '305'\n            (296): '306'\n            (297): '307'\n            (298): '308'\n            (299): '309'\n            (300): '310'\n            (301): '311'\n            (302): '312'\n            (303): '313'\n            (304): '314'\n            (305): '315'\n            (306): '316'\n            (307): '317'\n            (308): '318'\n            (309): '319'\n            (310): '320'\n            (311): '321'\n            (312): '322'\n            (313): '323'\n            (314): '324'\n            (315): '325'\n            (316): '326'\n            (317): '327'\n            (318): '328'\n            (319): '329'\n            (320): '330'\n            (321): '331'\n            (322): '332'\n            (323): '333'\n            (324): '334'\n            (325): '335'\n            (326): '336'\n            (327): '337'\n            (328): '338'\n            (329): '339'\n            (330): '340'\n            (331): '341'\n            (332): '342'\n            (333): '343'\n            (334): '344'\n            (335): '345'\n            (336): '346'\n            (337): '347'\n            (338): '348'\n            (339): '349'\n            (340): '350'\n            (341): '351'\n            (342): '352'\n            (343): '353'\n            (344): '354'\n            (345): '355'\n            (346): '356'\n            (347): '357'\n            (348): '358'\n            (349): '359'\n            (350): '360'\n            (351): '361'\n            (352): '362'\n            (353): '363'\n            (354): '364'\n            (355): '365'\n            (356): '366'\n            (357): '367'\n            (358): '368'\n            (359): '369'\n            (360): '370'\n            (361): '371'\n            (362): '372'\n            (363): '373'\n            (364): '374'\n            (365): '375'\n            (366): '376'\n            (367): '377'\n            (368): '378'\n            (369): '379'\n            (370): '380'\n            (371): '381'\n            (372): '382'\n            (373): '383'\n            (374): '384'\n            (375): '385'\n            (376): '386'\n            (377): '387'\n            (378): '388'\n            (379): '389'\n            (380): '390'\n            (381): '391'\n            (382): '392'\n            (383): '393'\n            (384): '394'\n            (385): '395'\n            (386): '396'\n            (387): '397'\n            (388): '398'\n            (389): '399'\n            (390): '400'\n            (391): '401'\n          )\n        )\n      )\n    )\n    (1): MLPBlock(\n      (layers): List(\n        (0): _Dense(\n          (dense): Dense(128, activation=relu, use_bias=True)\n        )\n        (1): _Dense(\n          (dense): Dense(64, activation=linear, use_bias=True)\n        )\n      )\n    )\n  )\n  (_prepare_features): PrepareFeatures(\n    (prepare_lists): PrepareListFeatures()\n  )\n) cannot be saved either because the input shape is not available or because the forward pass of the model is not defined.To define a forward pass, please override `Model.call()`. To specify an input shape, either call `build(input_shape)` directly, or call the model on actual data using `Model()`, `Model.fit()`, or `Model.predict()`. If you have a custom training step, please make sure to invoke the forward pass in train step through `Model.__call__`, i.e. `model(inputs)`, as opposed to `model.call()`."
     ]
    }
   ],
   "source": [
    "candidate_features = unique_rows_by_features(train, Tags.ITEM, Tags.ITEM_ID)\n",
    "\n",
    "topk_model = model.to_top_k_encoder(candidate_features, k=10, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17726f19-4593-4d8d-90f4-ba47df29b1bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a6a80-20f4-4fd6-80d6-491c4d5b207b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Custom [merlin-tensorflow] (Local)",
   "language": "python",
   "name": "nvcr.io_nvidia_merlin_merlin-tensorflow_23.08__python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
